---
sidebar: sidebar 
permalink: nvme_rhel_82.html 
keywords: nvme, linux, rhel, red hat, enterprise 
summary: Come configurare NVMe/FC host per RHEL 8.2 con ONTAP 
---
= Configurazione host NVMe/FC per RHEL 8.2 con ONTAP
:toc: macro
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toc: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/
:toc-position: content




== Supportabilità

NVMe/FC è supportato su ONTAP 9.6 o versione successiva per RHEL 8.2. L'host RHEL 8.2 esegue il traffico NVMe e SCSI attraverso le stesse porte dell'adattatore inizializzatore Fibre Channel (FC). Vedere link:https://hwu.netapp.com/Home/Index["Hardware Universe"^] Per un elenco di controller e adattatori FC supportati. Per l'elenco più aggiornato delle configurazioni e delle versioni supportate, consultare link:https://mysupport.netapp.com/matrix/["Matrice di interoperabilità NetApp"^].


NOTE: È possibile utilizzare le impostazioni di configurazione fornite in questo documento per configurare i client cloud connessi a. link:https://docs.netapp.com/us-en/cloud-manager-cloud-volumes-ontap/index.html["Cloud Volumes ONTAP"^] e. link:https://docs.netapp.com/us-en/cloud-manager-fsx-ontap/index.html["Amazon FSX per ONTAP"^].



== Limitazioni note

Per RHEL 8.2, il multipath NVMe in-kernel rimane disattivato per impostazione predefinita. Pertanto, è necessario attivarlo manualmente. I passaggi per farlo sono descritti nella sezione successiva, "abilitare NVMe/FC su RHEL 8.2".



== Abilitare NVMe/FC su RHEL 8.2

. Installare Red Hat Enterprise Linux 8.2 GA sul server.
+
Se si sta eseguendo l'aggiornamento da RHEL 8.1 a RHEL 8.2 utilizzando `yum update/upgrade`, il `/etc/nvme/host*` i file potrebbero andare persi. Per evitare la perdita di file, procedere come segue:

+
.. Eseguire il backup di `/etc/nvme/host*` file.
.. Se si dispone di una modifica manuale `udev` regola, rimuovilo:
+
[listing]
----
/lib/udev/rules.d/71-nvme-iopolicy-netapp-ONTAP.rules
----
.. Eseguire l'aggiornamento.
.. Al termine dell'aggiornamento, eseguire il seguente comando:
+
[listing]
----
yum remove nvme-cli
----
.. Ripristinare i file host in `/etc/nvme/`.
+
[listing]
----
yum install nvmecli
----
.. Copiare l'originale `/etc/nvme/host*` dal backup ai file host effettivi in `/etc/nvme/`.


. Una volta completata l'installazione, verificare di eseguire il kernel Red Hat Enterprise Linux specificato.
+
[listing]
----
# uname -r
4.18.0-193.el8.x86_64
----
+
Vedere link:https://mysupport.netapp.com/matrix/["Matrice di interoperabilità NetApp"^] per l'elenco più aggiornato delle versioni supportate.

. Installare il pacchetto nvme-cli.
+
[listing]
----
# rpm -qa|grep nvme-cli
nvme-cli-1.9.5.el8.x86_64
----
. Abilitare il multipath NVMe nel kernel.
+
[listing]
----
# grubby –args=nvme_core.multipath=Y –update-kernel /boot/vmlinuz-4.18.0-193.el8.x86_64
----
. Sull'host RHEL 8.2, controllare la stringa NQN host in /etc/nvme/hostnqn e verificare che corrisponda alla stringa NQN host per il sottosistema corrispondente sull'array ONTAP.
+
[listing]
----
# cat /etc/nvme/hostnqn
nqn.2014-08.org.nvmexpress:uuid:9ed5b327-b9fc-4cf5-97b3-1b5d986345d1


::> vserver nvme subsystem host show -vserver vs_fcnvme_141
Vserver      Subsystem        Host           NQN
----------- --------------- ----------- ---------------
  vs_fcnvme_141
    nvme_141_1
        nqn.2014-08.org.nvmexpress:uuid:9ed5b327-b9fc-4cf5-97b3-1b5d986345d1
----
+
Se le stringhe NQN host non corrispondono, utilizzare `vserver modify` Comando per aggiornare la stringa NQN host sul sottosistema dell'array ONTAP corrispondente in modo che corrisponda alla stringa NQM host da /etc/nvme/hostnqn sull'host.

. Riavviare l'host.
. Aggiornare `enable_foreign` impostazione _(opzionale)_.
+
Se si intende eseguire traffico NVMe e SCSI sullo stesso host coesistente RHEL 8.2, si consiglia di utilizzare il multipath NVMe nel kernel per gli spazi dei nomi ONTAP e il multipath dm per i LUN ONTAP, rispettivamente. È inoltre necessario inserire i namespace ONTAP in dm-multipath per impedire a dm-multipath di rivendicare questi dispositivi dello spazio dei nomi. A tale scopo, aggiungere il `enable_foreign` impostazione di /etc/multipath.conf, come mostrato di seguito.

+
[listing]
----
# cat /etc/multipath.conf
defaults {
   enable_foreign NONE
}
----
. Riavviare il daemon multipath eseguendo un `systemctl restart multipathd`.




== Configurare l'adattatore Broadcom FC per NVMe/FC

Per l'elenco aggiornato degli adattatori supportati, consultare la link:https://mysupport.netapp.com/matrix/["Matrice di interoperabilità NetApp"^].

.Fasi
. Verificare di utilizzare l'adattatore supportato.
+
[listing]
----
# cat /sys/class/scsi_host/host*/modelname
LPe32002-M2
LPe32002-M2
----
+
[listing]
----
# cat /sys/class/scsi_host/host*/modeldesc
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
----
. Verificare che `lpfc_enable_fc4_type` è impostato su "*3*".
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_enable_fc4_type
3
----
. Verificare che le porte dell'iniziatore siano attive e in esecuzione e che siano in grado di visualizzare i file LIF di destinazione.
+
[listing]
----
# cat /sys/class/fc_host/host*/port_name
0x100000109b1c1204
0x100000109b1c1205
----
+
[listing]
----
# cat /sys/class/fc_host/host*/port_state
Online
Online
----
+
[listing]
----
# cat /sys/class/scsi_host/host*/nvme_info
NVME Initiator Enabled
XRI Dist lpfc0 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc0 WWPN x100000109b1c1204 WWNN x200000109b1c1204 DID x011d00 ONLINE
NVME RPORT WWPN x203800a098dfdd91 WWNN x203700a098dfdd91 DID x010c07 TARGET DISCSRVC ONLINE
NVME RPORT WWPN x203900a098dfdd91 WWNN x203700a098dfdd91 DID x011507 TARGET DISCSRVC ONLINE
NVME Statistics
LS: Xmt 0000000f78 Cmpl 0000000f78 Abort 00000000
LS XMIT: Err 00000000 CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000002fe29bba Issue 000000002fe29bc4 OutIO 000000000000000a
abort 00001bc7 noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00001e15 Err 0000d906
NVME Initiator Enabled
XRI Dist lpfc1 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc1 WWPN x100000109b1c1205 WWNN x200000109b1c1205 DID x011900 ONLINE
NVME RPORT WWPN x203d00a098dfdd91 WWNN x203700a098dfdd91 DID x010007 TARGET DISCSRVC ONLINE
NVME RPORT WWPN x203a00a098dfdd91 WWNN x203700a098dfdd91 DID x012a07 TARGET DISCSRVC ONLINE
NVME Statistics
LS: Xmt 0000000fa8 Cmpl 0000000fa8 Abort 00000000
LS XMIT: Err 00000000 CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000002e14f170 Issue 000000002e14f17a OutIO 000000000000000a
abort 000016bb noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00001f50 Err 0000d9f8
----
. Abilita dimensione i/o 1 MB _(opzionale)_.
+
Il `lpfc_sg_seg_cnt` Il parametro deve essere impostato su 256 per consentire al driver lpfc di emettere richieste di i/o fino a 1 MB di dimensione.

+
[listing]
----
# cat /etc/modprobe.d/lpfc.conf
options lpfc lpfc_sg_seg_cnt=256
----
. Eseguire un `dracut -f` e riavviare l'host.
. Dopo l'avvio dell'host, verificare che lpfc_sg_seg_cnt sia impostato su 256.
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
256
----
. Verificare di utilizzare il firmware Broadcom lpfc consigliato e il driver inbox.
+
[listing]
----
# cat /sys/class/scsi_host/host*/fwrev
12.6.182.8, sli-4:2:c
12.6.182.8, sli-4:2:c
----
+
[listing]
----
# cat /sys/module/lpfc/version
0:12.6.0.2
----
. Verificare che `lpfc_enable_fc4_type` è impostato su "*3*".
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_enable_fc4_type
3
----
. Verificare che le porte dell'iniziatore siano attive e in esecuzione e che siano in grado di visualizzare i file LIF di destinazione.
+
[listing]
----
# cat /sys/class/fc_host/host*/port_name
0x100000109b1c1204
0x100000109b1c1205
----
+
[listing]
----
# cat /sys/class/fc_host/host*/port_state
Online
Online
----
+
[listing]
----
# cat /sys/class/scsi_host/host*/nvme_info
NVME Initiator Enabled
XRI Dist lpfc0 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc0 WWPN x100000109b1c1204 WWNN x200000109b1c1204 DID x011d00 ONLINE
NVME RPORT WWPN x203800a098dfdd91 WWNN x203700a098dfdd91 DID x010c07 TARGET DISCSRVC ONLINE
NVME RPORT WWPN x203900a098dfdd91 WWNN x203700a098dfdd91 DID x011507 TARGET DISCSRVC ONLINE
NVME Statistics
LS: Xmt 0000000f78 Cmpl 0000000f78 Abort 00000000
LS XMIT: Err 00000000 CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000002fe29bba Issue 000000002fe29bc4 OutIO 000000000000000a
abort 00001bc7 noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00001e15 Err 0000d906
NVME Initiator Enabled
XRI Dist lpfc1 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc1 WWPN x100000109b1c1205 WWNN x200000109b1c1205 DID x011900 ONLINE
NVME RPORT WWPN x203d00a098dfdd91 WWNN x203700a098dfdd91 DID x010007 TARGET DISCSRVC ONLINE
NVME RPORT WWPN x203a00a098dfdd91 WWNN x203700a098dfdd91 DID x012a07 TARGET DISCSRVC ONLINE
NVME Statistics
LS: Xmt 0000000fa8 Cmpl 0000000fa8 Abort 00000000
LS XMIT: Err 00000000 CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000002e14f170 Issue 000000002e14f17a OutIO 000000000000000a
abort 000016bb noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00001f50 Err 0000d9f8
----
. Abilita dimensione i/o 1 MB _(opzionale)_.
+
Il `lpfc_sg_seg_cnt` Il parametro deve essere impostato su 256 per consentire al driver lpfc di emettere richieste di i/o fino a 1 MB di dimensione.

+
[listing]
----
# cat /etc/modprobe.d/lpfc.conf
options lpfc lpfc_sg_seg_cnt=256
----
. Eseguire un `dracut -f` e riavviare l'host.
. Dopo l'avvio dell'host, verificare che lpfc_sg_seg_cnt sia impostato su 256.
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
256
----




== Validare NVMe/FC

. Verificare le seguenti impostazioni NVMe/FC.
+
[listing]
----
# cat /sys/module/nvme_core/parameters/multipath
Y
----
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys*/model
NetApp ONTAP Controller
NetApp ONTAP Controller
----
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys*/iopolicy
round-robin
round-robin
----
. Verificare che gli spazi dei nomi siano stati creati.
+
[listing]
----
# nvme list
Node SN Model Namespace Usage Format FW Rev
---------------- -------------------- -----------------------
/dev/nvme0n1 80BADBKnB/JvAAAAAAAC NetApp ONTAP Controller 1 53.69 GB / 53.69 GB 4 KiB + 0 B FFFFFFFF
----
. Verificare lo stato dei percorsi ANA.
+
[listing]
----
# nvme list-subsys/dev/nvme0n1
Nvme-subsysf0 – NQN=nqn.1992-08.com.netapp:sn.341541339b9511e8a9b500a098c80f09:subsystem.rhel_141_nvme_ss_10_0
\
+- nvme0 fc traddr=nn-0x202c00a098c80f09:pn-0x202d00a098c80f09 host_traddr=nn-0x20000090fae0ec61:pn-0x10000090fae0ec61 live optimized
+- nvme1 fc traddr=nn-0x207300a098dfdd91:pn-0x207600a098dfdd91 host_traddr=nn-0x200000109b1c1204:pn-0x100000109b1c1204 live inaccessible
+- nvme2 fc traddr=nn-0x207300a098dfdd91:pn-0x207500a098dfdd91 host_traddr=nn-0x200000109b1c1205:pn-0x100000109b1c1205 live optimized
+- nvme3 fc traddr=nn-0x207300a098dfdd91:pn-0x207700a098dfdd91 host traddr=nn-0x200000109b1c1205:pn-0x100000109b1c1205 live inaccessible
----
. Verificare il plug-in NetApp per i dispositivi ONTAP.
+
[listing]
----

# nvme netapp ontapdevices -o column
Device   Vserver  Namespace Path             NSID   UUID   Size
-------  -------- -------------------------  ------ ----- -----
/dev/nvme0n1   vs_nvme_10       /vol/rhel_141_vol_10_0/rhel_141_ns_10_0    1        55baf453-f629-4a18-9364-b6aee3f50dad   53.69GB

# nvme netapp ontapdevices -o json
{
   "ONTAPdevices" : [
   {
        Device" : "/dev/nvme0n1",
        "Vserver" : "vs_nvme_10",
        "Namespace_Path" : "/vol/rhel_141_vol_10_0/rhel_141_ns_10_0",
         "NSID" : 1,
         "UUID" : "55baf453-f629-4a18-9364-b6aee3f50dad",
         "Size" : "53.69GB",
         "LBA_Data_Size" : 4096,
         "Namespace_Size" : 13107200
    }
]
----




== LPFC verbose Logging

Impostare il driver lpfc per NVMe/FC.

.Fasi
. Impostare `lpfc_log_verbose` Impostazione del driver su uno dei seguenti valori per registrare gli eventi NVMe/FC.
+
[listing]
----
#define LOG_NVME 0x00100000 /* NVME general events. */
#define LOG_NVME_DISC 0x00200000 /* NVME Discovery/Connect events. */
#define LOG_NVME_ABTS 0x00400000 /* NVME ABTS events. */
#define LOG_NVME_IOERR 0x00800000 /* NVME IO Error events. */
----
. Dopo aver impostato i valori, eseguire `dracut-f` comandare e riavviare l'host.
. Verificare le impostazioni.
+
[listing]
----
# cat /etc/modprobe.d/lpfc.conf
options lpfc lpfc_log_verbose=0xf00083

# cat /sys/module/lpfc/parameters/lpfc_log_verbose
15728771
----

