---
sidebar: sidebar 
permalink: nvme_ol_91.html 
keywords:  
summary:  
---
= Configurazione host NVMe-of per Oracle Linux 9.1 con ONTAP
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/


[role="lead"]
NVMe over Fabrics (NVMe-of), inclusi NVMe over Fibre Channel (NVMe/FC) e altri trasporti, è supportato con Oracle Linux (OL) 9.1 con Ametric namespace Access (ANA). Negli ambienti NVMe-of, ANA è l'equivalente del multipathing ALUA in ambienti iSCSI e FC ed è implementato con multipath NVMe nel kernel.

Il seguente supporto è disponibile per la configurazione host NVMe-of per OL 9.1 con ONTAP:

* Supporto per NVMe su TCP (NVMe/TCP) oltre a NVMe/FC. Il plug-in NetApp nel pacchetto nvme-cli nativo visualizza i dettagli ONTAP per gli spazi dei nomi NVMe/FC e NVMe/TCP.
* Utilizzo di traffico NVMe e SCSI coesistente sullo stesso host su un determinato HBA (host bus adapter), senza le impostazioni esplicite di dm-multipath per impedire la richiesta di spazi dei nomi NVMe.


Per ulteriori informazioni sulle configurazioni supportate, consultare link:https://mysupport.netapp.com/matrix/["Tool di matrice di interoperabilità NetApp"^].



== Caratteristiche

* Oracle Linux 9.1 dispone di multipath NVMe in-kernel abilitato per gli spazi dei nomi NVMe per impostazione predefinita, pertanto non sono necessarie impostazioni esplicite.




== Limitazioni note

L'avvio SAN che utilizza il protocollo NVMe-of non è attualmente supportato.



== Convalidare le versioni software

È possibile utilizzare la seguente procedura per convalidare le versioni minime del software OL 9.1 supportate.

.Fasi
. Installare OL 9.1 GA sul server. Una volta completata l'installazione, verificare di eseguire il kernel OL 9.1 GA specificato.
+
[listing]
----
# uname -r
----
+
*Esempio di output:*

+
[listing]
----
5.15.0-3.60.5.1.el9uek.x86_64
----
. Installare `nvme-cli` pacchetto:
+
[listing]
----
# rpm -qa|grep nvme-cli
----
+
*Esempio di output:*

+
[listing]
----
nvme-cli-2.0-4.el9.x86_64
----
. Installare `libnvme` pacchetto:
+
[listing]
----
#rpm -qa|grep libnvme
----
+
*Esempio di output*

+
[listing]
----
libnvme-1.0-5.el9.x86_64.rpm
----
. Sull'host Oracle Linux 9.1, selezionare `hostnqn` stringa a. `/etc/nvme/hostnqn`:
+
[listing]
----
# cat /etc/nvme/hostnqn
----
+
*Esempio di output:*

+
[listing]
----
nqn.2014-08.org.nvmexpress:uuid:bc59d14c-47f3-11eb-b93c-3a68dd48673f
----
. Verificare che il `hostnqn` la stringa corrisponde a. `hostnqn` Stringa per il sottosistema corrispondente sull'array ONTAP:
+
[listing]
----
::> vserver nvme subsystem host show -vserver vs_ol_nvme
----
+
*Esempio di output:*

+
[listing]
----
Vserver     Subsystem          Host NQN
----------- --------------- ----------------------------------------------------------
vs_ol_nvme  nvme_ss_ol_1    nqn.2014-08.org.nvmexpress:uuid:bc59d14c-47f3-11eb-b93c-3a68dd48673f
----
+

NOTE: Se il `hostnqn` le stringhe non corrispondono, è possibile utilizzare `vserver modify` per aggiornare `hostnqn` Stringa sul sottosistema di array ONTAP corrispondente a `hostnqn` stringa da `/etc/nvme/hostnqn` sull'host.





== Configurare NVMe/FC

È possibile configurare NVMe/FC per gli adattatori Broadcom/Emulex o Marvell/Qlogic.

[role="tabbed-block"]
====
.Broadcom/Emulex
--
.Fasi
. Verificare di utilizzare il modello di adattatore supportato:
+
[listing]
----
# cat /sys/class/scsi_host/host*/modelname
----
+
*Esempio di output:*

+
[listing]
----
LPe32002-M2
LPe32002-M2
----
+
[listing]
----
# cat /sys/class/scsi_host/host*/modeldesc
----
+
*Esempio di output:*

+
[listing]
----
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
----
. Verificare di utilizzare il Broadcom consigliato `lpfc` firmware e driver della posta in arrivo:
+
[listing]
----
# cat /sys/class/scsi_host/host*/fwrev
12.8.614.23, sli-4:2:c
12.8.614.23, sli-4:2:c


# cat /sys/module/lpfc/version
0:14.0.0.1
----
+
Per l'elenco più aggiornato delle versioni firmware e dei driver della scheda di rete supportati, consultare link:https://mysupport.netapp.com/matrix/["Tool di matrice di interoperabilità NetApp"^].

. Verificare che `lpfc_enable_fc4_type` è impostato su `3`:
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_enable_fc4_type
3
----
. Verificare che le porte dell'iniziatore siano attive e in esecuzione e che siano visualizzate le LIF di destinazione:
+
[listing]
----
# cat /sys/class/fc_host/host*/port_name
0x100000109b3c081f
0x100000109b3c0820

# cat /sys/class/fc_host/host*/port_state
Online
Online
# cat /sys/class/scsi_host/host*/nvme_info
# cat /sys/class/scsi_host/host*/nvme_info
NVME Initiator Enabled
XRI Dist lpfc0 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc0 WWPN x100000109b1c1204 WWNN x200000109b1c1204 DID x011d00 ONLINE
NVME RPORT WWPN x203800a098dfdd91 WWNN x203700a098dfdd91 DID x010c07 TARGET DISCSRVC ONLINE
NVME RPORT WWPN x203900a098dfdd91 WWNN x203700a098dfdd91 DID x011507 TARGET DISCSRVC ONLINE
NVME Statistics
LS: Xmt 0000000f78 Cmpl 0000000f78 Abort 00000000
LS XMIT: Err 00000000 CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000002fe29bba Issue 000000002fe29bc4 OutIO 000000000000000a
abort 00001bc7 noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00001e15 Err 0000d906
NVME Initiator Enabled
XRI Dist lpfc1 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc1 WWPN x100000109b1c1205 WWNN x200000109b1c1205 DID x011900 ONLINE
NVME RPORT WWPN x203d00a098dfdd91 WWNN x203700a098dfdd91 DID x010007 TARGET DISCSRVC ONLINE
NVME RPORT WWPN x203a00a098dfdd91 WWNN x203700a098dfdd91 DID x012a07 TARGET DISCSRVC ONLINE
NVME Statistics
LS: Xmt 0000000fa8 Cmpl 0000000fa8 Abort 00000000
LS XMIT: Err 00000000 CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000002e14f170 Issue 000000002e14f17a OutIO 000000000000000a
abort 000016bb noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00001f50 Err 0000d9f8

----


--
.Adattatore FC Marvell/QLogic per NVMe/FC
--
Il driver inbox qla2xxx nativo incluso nel kernel OL 9,1 GA ha le ultime correzioni upstream. Queste correzioni sono essenziali per il supporto di ONTAP.

.Fasi
. Verificare che siano in esecuzione le versioni del firmware e del driver dell'adattatore supportate:
+
[listing]
----
# cat /sys/class/fc_host/host*/symbolic_name
QLE2742 FW:v9.18.02 DVR:v10.02.00.106-k
QLE2742 FW:v9.18.02 DVR:v10.02.00.106-k
----
. Verificare che `ql2xnvmeenable` è impostato. Ciò consente all'adattatore Marvell di funzionare come iniziatore NVMe/FC:
+
[listing]
----
# cat /sys/module/qla2xxx/parameters/ql2xnvmeenable
1
----


--
====


=== Abilita dimensione i/o 1 MB (opzionale)

ONTAP riporta un MDTS (MAX Data Transfer Size) di 8 nei dati del controller di identificazione. Ciò significa che le dimensioni massime delle richieste i/o possono essere fino a 1MB MB. Per emettere richieste di i/o di dimensioni pari a 1 MB per un host Broadcom NVMe/FC, è necessario aumentare il `lpfc` valore del `lpfc_sg_seg_cnt` parametro a 256 dal valore predefinito di 64.


NOTE: I seguenti passaggi non si applicano agli host Qlogic NVMe/FC.

.Fasi
. Impostare il `lpfc_sg_seg_cnt` parametro su 256:
+
[listing]
----
cat /etc/modprobe.d/lpfc.conf
----
+
.Output di esempio
[listing]
----
options lpfc lpfc_sg_seg_cnt=256
----
. Eseguire il `dracut -f` comando e riavviare l'host:
. Verificare che `lpfc_sg_seg_cnt` sia 256:
+
[listing]
----
cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
----
+
Il valore previsto è 256.





== Configurare NVMe/TCP

NVMe/TCP non dispone della funzionalità di connessione automatica. Pertanto, se un percorso non viene eseguito e non viene ripristinato entro il periodo di timeout predefinito di 10 minuti, NVMe/TCP non può riconnettersi automaticamente. Per evitare un timeout, impostare il periodo di ripetizione degli eventi di failover su almeno 30 minuti.

.Fasi
. Verificare che la porta iniziatore possa recuperare i dati della pagina del registro di rilevamento attraverso le LIF NVMe/TCP supportate:
+
[listing]
----
nvme discover -t tcp -w host-traddr -a traddr
----
+
*Esempio di output:*

+
[listing]
----
#  nvme discover -t tcp -w 192.168.6.13 -a 192.168.6.15
Discovery Log Number of Records 6, Generation counter 8
=====Discovery Log Entry 0======
trtype: tcp
adrfam: ipv4
subtype: unrecognized
treq: not specified
portid: 0
trsvcid: 8009
subnqn: nqn.1992-08.com.netapp:sn.1c6ac66338e711eda41dd039ea3ad566:discovery
traddr: 192.168.6.17
sectype: none
=====Discovery Log Entry 1======
trtype: tcp
adrfam: ipv4
subtype: unrecognized
treq: not specified
portid: 1
trsvcid: 8009
subnqn: nqn.1992-08.com.netapp:sn.1c6ac66338e711eda41dd039ea3ad566:discovery
traddr: 192.168.5.17
sectype: none
=====Discovery Log Entry 2======
trtype: tcp
adrfam: ipv4
subtype: unrecognized
treq: not specified
portid: 2
trsvcid: 8009
subnqn: nqn.1992-08.com.netapp:sn.1c6ac66338e711eda41dd039ea3ad566:discovery
traddr: 192.168.6.15
sectype: none
=====Discovery Log Entry 3======
trtype: tcp
adrfam: ipv4
subtype: nvme subsystem
treq: not specified
portid: 0
trsvcid: 4420
subnqn: nqn.1992-08.com.netapp:sn.1c6ac66338e711eda41dd039ea3ad566:subsystem.host_95
traddr: 192.168.6.17
sectype: none
..........

----
. Verificare che le altre combinazioni LIF iniziatore-destinazione NVMe/TCP possano recuperare correttamente i dati della pagina del registro di rilevamento:
+
[listing]
----
nvme discover -t tcp -w host-traddr -a traddr
----
+
*Esempio di output:*

+
[listing]
----
# nvme discover -t tcp -w 192.168.5.13 -a 192.168.5.15
# nvme discover -t tcp -w 192.168.5.13 -a 192.168.5.17
# nvme discover -t tcp -w 192.168.6.13 -a 192.168.6.15
# nvme discover -t tcp -w 192.168.6.13 -a 192.168.6.17
----
. Eseguire `nvme connect-all` Controlla tutti i LIF di destinazione dell'iniziatore NVMe/TCP supportati nei nodi e imposta il periodo di timeout per la perdita del controller per almeno 30 minuti o 1800 secondi:
+
[listing]
----
nvme connect-all -t tcp -w host-traddr -a traddr -l 1800
----
+
*Esempio di output:*

+
[listing]
----
# nvme connect-all -t tcp -w 192.168.5.13 -a 192.168.5.15 -l 1800
# nvme connect-all -t tcp -w 192.168.5.13 -a 192.168.5.17 -l 1800
# nvme connect-all -t tcp -w 192.168.6.13 -a 192.168.6.15 -l 1800
# nvme connect-all -t tcp -w 192.168.6.13 -a 192.168.6.17 -l 1800
----




== Validare NVMe-of

È possibile utilizzare la seguente procedura per convalidare NVMe-of.

.Fasi
. Verificare le seguenti impostazioni NVMe/FC sull'host OL 9.1:
+
[listing]
----
# cat /sys/module/nvme_core/parameters/multipath
Y
----
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys*/model
NetApp ONTAP Controller
NetApp ONTAP Controller
----
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys*/iopolicy
round-robin
round-robin
----
. Verificare che gli spazi dei nomi siano stati creati e rilevati correttamente sull'host:
+
[listing]
----
# nvme list
----
+
*Esempio di output:*

+
[listing]
----
Node         SN                   Model
---------------------------------------------------------
/dev/nvme0n1 814vWBNRwf9HAAAAAAAB NetApp ONTAP Controller
/dev/nvme0n2 814vWBNRwf9HAAAAAAAB NetApp ONTAP Controller
/dev/nvme0n3 814vWBNRwf9HAAAAAAAB NetApp ONTAP Controller


Namespace Usage    Format             FW             Rev
-----------------------------------------------------------
1                 85.90 GB / 85.90 GB  4 KiB + 0 B   FFFFFFFF
2                 85.90 GB / 85.90 GB  24 KiB + 0 B  FFFFFFFF
3                 85.90 GB / 85.90 GB  4 KiB + 0 B   FFFFFFFF
----
. Verificare che lo stato del controller di ciascun percorso sia attivo e che abbia lo stato ANA corretto:
+
[role="tabbed-block"]
====
.NVMe/FC
--
[listing]
----
# nvme list-subsys /dev/nvme0n1
----
*Esempio di output:*

[listing]
----
nvme-subsys0 - NQN=nqn.1992-08.com.netapp:sn.5f5f2c4aa73b11e9967e00a098df41bd:subsystem.nvme_ss_ol_1
\
+- nvme0 fc traddr=nn-0x203700a098dfdd91:pn-0x203800a098dfdd91 host_traddr=nn-0x200000109b1c1204:pn-0x100000109b1c1204 live inaccessible
+- nvme1 fc traddr=nn-0x203700a098dfdd91:pn-0x203900a098dfdd91 host_traddr=nn-0x200000109b1c1204:pn-0x100000109b1c1204 live inaccessible
+- nvme2 fc traddr=nn-0x203700a098dfdd91:pn-0x203a00a098dfdd91 host_traddr=nn-0x200000109b1c1205:pn-0x100000109b1c1205 live optimized
+- nvme3 fc traddr=nn-0x203700a098dfdd91:pn-0x203d00a098dfdd91 host_traddr=nn-0x200000109b1c1205:pn-0x100000109b1c1205 live optimized
----
--
.NVMe/TCP
--
[listing]
----
nvme list-subsys /dev/nvme1n22
----
*Esempio di output*

[listing]
----
nvme-subsys1 - NQN=nqn.1992-08.com.netapp:sn.68c036aaa3cf11edbb95d039ea243511:subsystem.tcp
\
+- nvme2 tcp traddr=192.168.8.49,trsvcid=4420,host_traddr=192.168.8.1 live optimized
+- nvme3 tcp traddr=192.168.8.48,trsvcid=4420,host_traddr=192.168.8.1 live optimized
+- nvme6 tcp traddr=192.168.9.49,trsvcid=4420,host_traddr=192.168.9.1 live non-optimized
+- nvme7 tcp traddr=192.168.9.48,trsvcid=4420,host_traddr=192.168.9.1 live non-optimized
----
--
====
. Verificare che il plug-in NetApp visualizzi i valori corretti per ciascun dispositivo dello spazio dei nomi ONTAP:
+
[role="tabbed-block"]
====
.Colonna
--
[listing]
----
# nvme netapp ontapdevices -o column
----
*Esempio di output:*

[listing]
----
Device        Vserver   Namespace Path
----------------------- ------------------------------
/dev/nvme0n1   vs_ol_nvme  /vol/ol_nvme_vol_1_1_0/ol_nvme_ns
/dev/nvme0n2   vs_ol_nvme  /vol/ol_nvme_vol_1_0_0/ol_nvme_ns
/dev/nvme0n3   vs_ol_nvme  /vol/ol_nvme_vol_1_1_1/ol_nvme_ns


NSID       UUID                                   Size
------------------------------------------------------------
1          72b887b1-5fb6-47b8-be0b-33326e2542e2   85.90GB
2          04bf9f6e-9031-40ea-99c7-a1a61b2d7d08   85.90GB
3          264823b1-8e03-4155-80dd-e904237014a4   85.90GB
----
--
.JSON
--
[listing]
----
# nvme netapp ontapdevices -o json
----
*Esempio di output*

[listing]
----
{
"ONTAPdevices" : [
    {
        "Device" : "/dev/nvme0n1",
        "Vserver" : "vs_ol_nvme",
        "Namespace_Path" : "/vol/ol_nvme_vol_1_1_0/ol_nvme_ns",
        "NSID" : 1,
        "UUID" : "72b887b1-5fb6-47b8-be0b-33326e2542e2",
        "Size" : "85.90GB",
        "LBA_Data_Size" : 4096,
        "Namespace_Size" : 20971520
    },
    {
        "Device" : "/dev/nvme0n2",
        "Vserver" : "vs_ol_nvme",
        "Namespace_Path" : "/vol/ol_nvme_vol_1_0_0/ol_nvme_ns",
        "NSID" : 2,
        "UUID" : "04bf9f6e-9031-40ea-99c7-a1a61b2d7d08",
        "Size" : "85.90GB",
        "LBA_Data_Size" : 4096,
        "Namespace_Size" : 20971520
      },
      {
         "Device" : "/dev/nvme0n3",
         "Vserver" : "vs_ol_nvme",
         "Namespace_Path" : "/vol/ol_nvme_vol_1_1_1/ol_nvme_ns",
         "NSID" : 3,
         "UUID" : "264823b1-8e03-4155-80dd-e904237014a4",
         "Size" : "85.90GB",
         "LBA_Data_Size" : 4096,
         "Namespace_Size" : 20971520
       },
  ]
}
----
--
====




== Problemi noti

La configurazione dell'host NVMe-of per OL 9.1 con ONTAP presenta i seguenti problemi noti:

[cols=""20"]
|===
| ID bug NetApp | Titolo | Descrizione 


| 1536937 | `nvme list-subsys` Il comando stampa i controller NVMe ripetuti per un sottosistema | Il `nvme list-subsys` Il comando dovrebbe restituire un elenco univoco di controller NVMe associati a un determinato sottosistema. In Oracle Linux 9.1 `nvme list-subsys` Il comando restituisce i controller NVMe con il rispettivo stato ANA (Asymmetric namespace access) per tutti gli spazi dei nomi che appartengono a un determinato sottosistema. Tuttavia, sarebbe utile visualizzare le voci univoche del controller NVMe con lo stato del percorso se si elenca la sintassi del comando del sottosistema per un dato namespace perché lo stato ANA è un attributo per-namespace. 


| 1539101 | Gli host Oracle Linux 9.1 NVMe-of non riescono a creare un controller di rilevamento persistente | Su host Oracle Linux 9.1 NVMe-of, è possibile utilizzare `nvme discover -p` Per creare controller di rilevamento persistenti (PDC). Quando si utilizza questo comando, è necessario creare un PDC per ogni combinazione initiator-target. Tuttavia, se si esegue Oracle Linux 9.1 su un host NVMe-of, la creazione del PDC non riesce quando `nvme discover -p` il comando viene eseguito. 
|===